{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12ef6ae-e40e-414b-9e35-9f9aa65fbfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\akshata pandit\\appdata\\roaming\\python\\python311\\site-packages (3.4.4)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\akshata pandit\\appdata\\roaming\\python\\python311\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b1cb07-e76c-4e77-abc1-e08257cce52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "ERROR: Could not find a version that satisfies the requirement scala (from versions: none)\n",
      "ERROR: No matching distribution found for scala\n"
     ]
    }
   ],
   "source": [
    "pip install scala\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8dd88f-f99b-4ed6-a725-a8c6f774db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import logging \n",
    "import os\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col,lit,when,avg,count,sum\n",
    "from pyspark.sql import functions as F\n",
    "from collections import Counter\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = 'C:\\\\java'\n",
    "import os\n",
    "os.environ['HADOOP_HOME'] = 'C:\\\\hadoop\\\\hadoop-3.4.1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set environment variablesp3\n",
    "os.environ['PATH'] += os.pathsep +\"C:\\\\hadoop\\\\hadoop-3.4.1\\\\bin\"\n",
    "os.environ['HIVE_HOME'] = 'C:\\\\hive'  \n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HIVE_HOME'], 'bin')\n",
    "os.environ['CLASSPATH'] = os.pathsep.join([os.environ.get('HIVE_HOME') + '\\\\lib\\\\*', os.environ.get('HADOOP_HOME') + '\\\\share\\\\hadoop\\\\common\\\\*'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0215be7d-b019-4615-912f-1017c2222766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:26:42,945 - INFO - Initializing Spark Session\n",
      "2025-01-07 16:26:50,424 - INFO - Spark Session Created Successfully\n",
      "2025-01-07 16:26:50,427 - INFO - Spark SQL Warehouse Directory: C:\\Users\\Akshata Pandit\\spark-warehouse\n",
      "2025-01-07 16:26:50,429 - INFO - Hive support is enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "def create_spark_session(app_name=\"Data Warehouse Project\", warehouse_dir=None, enable_hive_support=False, hive_metastore_uri=None):\n",
    "    # Initialize logger\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(app_name)\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Initializing Spark Session\")\n",
    "\n",
    "        # Initialize SparkSession builder\n",
    "        builder = SparkSession.builder.appName(app_name)\n",
    "\n",
    "        # Set warehouse directory\n",
    "        if warehouse_dir is None:\n",
    "            warehouse_dir = os.path.join(os.getcwd(), \"spark-warehouse\")\n",
    "        builder.config(\"spark.sql.warehouse.dir\", warehouse_dir)\n",
    "\n",
    "        # Add additional configurations\n",
    "        builder.config(\"spark.executor.memory\", \"4g\")\n",
    "        builder.config(\"spark.driver.memory\", \"16g\")\n",
    "        builder.config(\"spark.driver.extraJavaOptions\", \"-XX:+UseCompressedOops\")\n",
    "        builder.config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "\n",
    "        # Set environment variables for Java, Hadoop, and Hive\n",
    "        os.environ['JAVA_HOME'] = 'C:\\\\java'  # Update with your Java installation path\n",
    "        os.environ['HADOOP_HOME'] = 'C:\\\\hadoop\\\\hadoop-3.4.1'  # Update with your Hadoop installation path\n",
    "        os.environ['HIVE_HOME'] = 'C:\\\\hive\\\\apache-hive-3.1.2-bin'  # Update with your Hive installation path\n",
    "        os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HADOOP_HOME'], 'bin')\n",
    "        os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HIVE_HOME'], 'bin')\n",
    "        os.environ['CLASSPATH'] = os.pathsep.join([os.environ.get('HIVE_HOME') + '\\\\lib\\\\*', os.environ.get('HADOOP_HOME') + '\\\\share\\\\hadoop\\\\common\\\\*'])\n",
    "\n",
    "        # Enable Hive support if requested\n",
    "        if enable_hive_support:\n",
    "            if hive_metastore_uri:\n",
    "                builder.config(\"hive.metastore.uris\", hive_metastore_uri)  # Remote Metastore URI\n",
    "            else:\n",
    "                logger.warning(\"Hive support enabled, but no metastore URI provided. Using default Hive configuration.\")\n",
    "            builder.enableHiveSupport()\n",
    "\n",
    "        # Create SparkSession\n",
    "        spark = builder.getOrCreate()\n",
    "\n",
    "        logger.info(\"Spark Session Created Successfully\")\n",
    "        logger.info(f\"Spark SQL Warehouse Directory: {warehouse_dir}\")\n",
    "        if enable_hive_support:\n",
    "            logger.info(\"Hive support is enabled.\")\n",
    "\n",
    "        return spark\n",
    "\n",
    "    except AnalysisException as ae:\n",
    "        logger.error(f\"AnalysisException: {str(ae)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while creating the Spark session: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage of the session creation:\n",
    "try:\n",
    "    spark = create_spark_session(\n",
    "        app_name=\"My Data Warehouse\", \n",
    "        enable_hive_support=True, \n",
    "        hive_metastore_uri=\"thrift://localhost:9083\"  # Use your actual metastore URI here\n",
    "    )\n",
    "    # Now you can run your analytics queries\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to initialize Spark Session: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79bdb6f-5ddc-4dc0-a19b-353ee6ebde00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:27:15,738 - INFO - Total rows processed: 1058\n",
      "2025-01-07 16:27:15,741 - INFO - Null counts: [Row(Age=0, Attrition=0, BusinessTravel=0, DailyRate=0, Department=0, DistanceFromHome=0, Education=0, EducationField=0, EmployeeCount=0, EmployeeNumber=0, EnvironmentSatisfaction=0, Gender=0, HourlyRate=0, JobInvolvement=0, JobLevel=0, JobRole=0, JobSatisfaction=0, MaritalStatus=0, MonthlyIncome=0, MonthlyRate=0, NumCompaniesWorked=0, Over18=0, OverTime=0, PercentSalaryHike=0, PerformanceRating=0, RelationshipSatisfaction=0, StandardHours=0, StockOptionLevel=0, TotalWorkingYears=0, TrainingTimesLastYear=0, WorkLifeBalance=0, YearsAtCompany=0, YearsInCurrentRole=0, YearsSinceLastPromotion=0, YearsWithCurrManager=0)]\n",
      "2025-01-07 16:27:16,410 - INFO - Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when\n",
    "import logging\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"SparkJobMonitor\")\n",
    "\n",
    "# Email Alert Function\n",
    "def send_email_alert(subject, body):\n",
    "    sender_email = \"akshatapandit7@gmail.com\"\n",
    "    receiver_email = \"akshata.codes2332@gmail.com\"\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    smtp_port = 587\n",
    "    smtp_password = \"your_email_password\"\n",
    "\n",
    "    msg = EmailMessage()\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "    msg.set_content(body)\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, smtp_password)\n",
    "            server.send_message(msg)\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to send email alert: {e}\")\n",
    "\n",
    "# Spark Job Execution and Monitoring\n",
    "def run_spark_job():\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"AlternativeSparkMonitoring\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    try:\n",
    "        # Replace with your data path\n",
    "        data_path = \"C:\\\\excels\\\\train.csv\"\n",
    "        df = spark.read.csv(data_path, header=True)\n",
    "\n",
    "        # Perform simple data validation\n",
    "        total_rows = df.count()\n",
    "        null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).collect()\n",
    "\n",
    "        logger.info(f\"Total rows processed: {total_rows}\")\n",
    "        logger.info(f\"Null counts: {null_counts}\")\n",
    "\n",
    "        # Alert if row count is below a threshold\n",
    "        if total_rows < 1000:\n",
    "            alert_message = f\"ALERT: Row count below threshold! Processed rows: {total_rows}\"\n",
    "            logger.warning(alert_message)\n",
    "            send_email_alert(\"Row Count Alert\", alert_message)\n",
    "\n",
    "        # Alert if null values exceed a threshold\n",
    "        for column, null_count in zip(df.columns, null_counts[0]):\n",
    "            if null_count > 0:\n",
    "                alert_message = f\"ALERT: Null values detected in column '{column}': {null_count}\"\n",
    "                logger.warning(alert_message)\n",
    "                send_email_alert(\"Data Quality Alert\", alert_message)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Spark job encountered an error: {e}\")\n",
    "        send_email_alert(\"Job Failure Alert\", f\"Spark job failed with error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        spark.stop()\n",
    "        logger.info(\"Spark session stopped.\")\n",
    "\n",
    "# Run the Spark job\n",
    "if __name__ == \"__main__\":\n",
    "    run_spark_job()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1101bc3-f3af-4a5b-aa7f-9243f1ec4acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:27:16,431 - INFO - Initializing Spark Session\n",
      "2025-01-07 16:27:16,434 - WARNING - Hive support enabled, but no metastore URI provided. Using default Hive configuration.\n",
      "2025-01-07 16:27:16,976 - INFO - Spark Session Created Successfully\n",
      "2025-01-07 16:27:16,978 - INFO - Spark SQL Warehouse Directory:  C:\\BigDataOutput\n",
      "2025-01-07 16:27:16,980 - INFO - Hive support is enabled.\n"
     ]
    }
   ],
   "source": [
    "warehouse_directory = \" C:\\\\BigDataOutput\"  \n",
    "spark = create_spark_session(warehouse_dir=warehouse_directory, enable_hive_support=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1b223b-680c-42a0-95db-228265d4e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:27:17,015 - INFO - Ingesting data from C:\\excels\\train.csv as csv\n",
      "2025-01-07 16:27:18,470 - INFO - Data ingestion successful: C:\\excels\\train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|Age|Attrition|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|\n",
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "| 41|        1|    Travel_Rarely|     1102|               Sales|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|     Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "| 49|        0|Travel_Frequently|      279|Research & Develo...|               8|        1| Life Sciences|            1|             2|                      3|  Male|        61|             2|       2|  Research Scientist|              2|      Married|         5130|      24907|                 1|     Y|      No|               23|                4|                       4|           80|               1|               10|                    3|              3|            10|                 7|                      1|                   7|\n",
      "| 37|        1|    Travel_Rarely|     1373|Research & Develo...|               2|        2|         Other|            1|             4|                      4|  Male|        92|             2|       1|Laboratory Techni...|              3|       Single|         2090|       2396|                 6|     Y|     Yes|               15|                3|                       2|           80|               0|                7|                    3|              3|             0|                 0|                      0|                   0|\n",
      "| 33|        0|Travel_Frequently|     1392|Research & Develo...|               3|        4| Life Sciences|            1|             5|                      4|Female|        56|             3|       1|  Research Scientist|              3|      Married|         2909|      23159|                 1|     Y|     Yes|               11|                3|                       3|           80|               0|                8|                    3|              3|             8|                 7|                      3|                   0|\n",
      "| 27|        0|    Travel_Rarely|      591|Research & Develo...|               2|        1|       Medical|            1|             7|                      1|  Male|        40|             3|       1|Laboratory Techni...|              2|      Married|         3468|      16632|                 9|     Y|      No|               12|                3|                       4|           80|               1|                6|                    3|              3|             2|                 2|                      2|                   2|\n",
      "| 32|        0|Travel_Frequently|     1005|Research & Develo...|               2|        2| Life Sciences|            1|             8|                      4|  Male|        79|             3|       1|Laboratory Techni...|              4|       Single|         3068|      11864|                 0|     Y|      No|               13|                3|                       3|           80|               0|                8|                    2|              2|             7|                 7|                      3|                   6|\n",
      "| 59|        0|    Travel_Rarely|     1324|Research & Develo...|               3|        3|       Medical|            1|            10|                      3|Female|        81|             4|       1|Laboratory Techni...|              1|      Married|         2670|       9964|                 4|     Y|     Yes|               20|                4|                       1|           80|               3|               12|                    3|              2|             1|                 0|                      0|                   0|\n",
      "| 30|        0|    Travel_Rarely|     1358|Research & Develo...|              24|        1| Life Sciences|            1|            11|                      4|  Male|        67|             3|       1|Laboratory Techni...|              3|     Divorced|         2693|      13335|                 1|     Y|      No|               22|                4|                       2|           80|               1|                1|                    2|              3|             1|                 0|                      0|                   0|\n",
      "| 38|        0|Travel_Frequently|      216|Research & Develo...|              23|        3| Life Sciences|            1|            12|                      4|  Male|        44|             2|       3|Manufacturing Dir...|              3|       Single|         9526|       8787|                 0|     Y|      No|               21|                4|                       2|           80|               0|               10|                    2|              3|             9|                 7|                      1|                   8|\n",
      "| 36|        0|    Travel_Rarely|     1299|Research & Develo...|              27|        3|       Medical|            1|            13|                      3|  Male|        94|             3|       2|Healthcare Repres...|              3|      Married|         5237|      16577|                 6|     Y|      No|               13|                3|                       2|           80|               2|               17|                    3|              2|             7|                 7|                      7|                   7|\n",
      "| 35|        0|    Travel_Rarely|      809|Research & Develo...|              16|        3|       Medical|            1|            14|                      1|  Male|        84|             4|       1|Laboratory Techni...|              2|      Married|         2426|      16479|                 0|     Y|      No|               13|                3|                       3|           80|               1|                6|                    5|              3|             5|                 4|                      0|                   3|\n",
      "| 29|        0|    Travel_Rarely|      153|Research & Develo...|              15|        2| Life Sciences|            1|            15|                      4|Female|        49|             2|       2|Laboratory Techni...|              3|       Single|         4193|      12682|                 0|     Y|     Yes|               12|                3|                       4|           80|               0|               10|                    3|              3|             9|                 5|                      0|                   8|\n",
      "| 31|        0|    Travel_Rarely|      670|Research & Develo...|              26|        1| Life Sciences|            1|            16|                      1|  Male|        31|             3|       1|  Research Scientist|              3|     Divorced|         2911|      15170|                 1|     Y|      No|               17|                3|                       4|           80|               1|                5|                    1|              2|             5|                 2|                      4|                   3|\n",
      "| 34|        0|    Travel_Rarely|     1346|Research & Develo...|              19|        2|       Medical|            1|            18|                      2|  Male|        93|             3|       1|Laboratory Techni...|              4|     Divorced|         2661|       8758|                 0|     Y|      No|               11|                3|                       3|           80|               1|                3|                    2|              3|             2|                 2|                      1|                   2|\n",
      "| 28|        1|    Travel_Rarely|      103|Research & Develo...|              24|        3| Life Sciences|            1|            19|                      3|  Male|        50|             2|       1|Laboratory Techni...|              3|       Single|         2028|      12947|                 5|     Y|     Yes|               14|                3|                       2|           80|               0|                6|                    4|              3|             4|                 2|                      0|                   3|\n",
      "| 29|        0|    Travel_Rarely|     1389|Research & Develo...|              21|        4| Life Sciences|            1|            20|                      2|Female|        51|             4|       3|Manufacturing Dir...|              1|     Divorced|         9980|      10195|                 1|     Y|      No|               11|                3|                       3|           80|               1|               10|                    1|              3|            10|                 9|                      8|                   8|\n",
      "| 32|        0|    Travel_Rarely|      334|Research & Develo...|               5|        2| Life Sciences|            1|            21|                      1|  Male|        80|             4|       1|  Research Scientist|              2|     Divorced|         3298|      15053|                 0|     Y|     Yes|               12|                3|                       4|           80|               2|                7|                    5|              2|             6|                 2|                      0|                   5|\n",
      "| 22|        0|       Non-Travel|     1123|Research & Develo...|              16|        2|       Medical|            1|            22|                      4|  Male|        96|             4|       1|Laboratory Techni...|              4|     Divorced|         2935|       7324|                 1|     Y|     Yes|               13|                3|                       2|           80|               2|                1|                    2|              2|             1|                 0|                      0|                   0|\n",
      "| 53|        0|    Travel_Rarely|     1219|               Sales|               2|        4| Life Sciences|            1|            23|                      1|Female|        78|             2|       4|             Manager|              4|      Married|        15427|      22021|                 2|     Y|      No|               16|                3|                       3|           80|               0|               31|                    3|              3|            25|                 8|                      3|                   7|\n",
      "| 38|        0|    Travel_Rarely|      371|Research & Develo...|               2|        3| Life Sciences|            1|            24|                      4|  Male|        45|             3|       1|  Research Scientist|              4|       Single|         3944|       4306|                 5|     Y|     Yes|               11|                3|                       3|           80|               0|                6|                    3|              3|             3|                 2|                      1|                   2|\n",
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ingest_data(\n",
    "    spark:SparkSession,\n",
    "    file_path:str,\n",
    "    schema:StructType=None,\n",
    "    file_format:str=\"csv\",\n",
    "options:dict=None) -> DataFrame:\n",
    "    logger = logging.getLogger(\"Data Ingestion\") \n",
    "    logger.info(f\"Ingesting data from {file_path} as {file_format}\") \n",
    "    if options is None:\n",
    "        options = {}\n",
    "\n",
    "    try: \n",
    "        if file_format.lower() == \"csv\": \n",
    "\n",
    "            df = spark.read.csv(file_path, schema=schema, **options) \n",
    "\n",
    "        elif file_format.lower() == \"json\": \n",
    "\n",
    "            df = spark.read.json(file_path, schema=schema, **options) \n",
    "\n",
    "        elif file_format.lower() == \"parquet\": \n",
    "\n",
    "            df = spark.read.parquet(file_path, **options) \n",
    "        else: \n",
    "            raise ValueError(f\"Unsupported file format: {file_format}\") \n",
    "\n",
    "        logger.info(f\"Data ingestion successful: {file_path}\") \n",
    "        return df \n",
    "    except Exception as e: \n",
    "        logger.error(f\"Error during data ingestion: {e}\") \n",
    "        raise \n",
    "csv_options = { \n",
    "\n",
    "    \"header\": \"true\", \n",
    "\n",
    "    \"inferSchema\": \"true\" \n",
    "\n",
    "} \n",
    "data_path = \"C:\\\\excels\\\\train.csv\"\n",
    "\n",
    "\n",
    "data_frame = ingest_data(spark, file_path=data_path, file_format=\"csv\", options=csv_options) \n",
    "\n",
    "data_frame.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0dae975-04f4-49b3-83d7-80bad0da47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df:DataFrame,columns_to_drop:list=None,default_values:dict=None)-> DataFrame:\n",
    "        if columns_to_drop:\n",
    "            df=df.drop(*columns_to_drop)\n",
    "        if default_values:\n",
    "            for col_name,default_val in default_values.items():\n",
    "                df=df.withColumn(col_name,when(col(col_name).isNull(),lit(default_val)).otherwise(col(col_name)))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f806819b-2ace-409c-888e-1e31b3dcb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def aggregate_data(df: DataFrame, group_by_cols: list, agg_funcs: dict) -> DataFrame:\n",
    "    \n",
    "    agg_exprs = [func(F.col(col_name)).alias(f\"{col_name}_{func.__name__}\") for col_name, func in agg_funcs.items()]\n",
    "   \n",
    "    return df.groupBy(*group_by_cols).agg(*agg_exprs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17384c56-65e0-403c-ad3f-5c53c6ba4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(df1:DataFrame,df2:DataFrame,join_col:str,join_type:str=\"inner\")->DataFrame:\n",
    "    common_columns = [col for col in df1.columns if col in df2.columns and col != join_col]\n",
    "    \n",
    "    \n",
    "    df2_renamed = df2.select([F.col(c).alias(f\"{c}_df2\") if c in common_columns else F.col(c) for c in df2.columns])\n",
    "    \n",
    "    \n",
    "    joined_df = df1.join(df2_renamed, on=join_col, how=join_type)\n",
    "    \n",
    "  \n",
    "    for col in common_columns:\n",
    "        joined_df = joined_df.withColumn(col, F.coalesce(F.col(col), F.col(f\"{col}_df2\")))\n",
    "        joined_df = joined_df.drop(f\"{col}_df2\")  # Drop the renamed df2 columns\n",
    "    \n",
    "    return joined_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d533e5-66e8-41b6-8f32-3df91abfd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=clean_data(data_frame,columns_to_drop=[\"id\"],\n",
    "                        default_values=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf36b2e8-6d52-48c5-8677-872ad6007947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Attrition: integer (nullable = true)\n",
      " |-- BusinessTravel: string (nullable = true)\n",
      " |-- DailyRate: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- DistanceFromHome: integer (nullable = true)\n",
      " |-- Education: integer (nullable = true)\n",
      " |-- EducationField: string (nullable = true)\n",
      " |-- EmployeeCount: integer (nullable = true)\n",
      " |-- EmployeeNumber: integer (nullable = true)\n",
      " |-- EnvironmentSatisfaction: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- HourlyRate: integer (nullable = true)\n",
      " |-- JobInvolvement: integer (nullable = true)\n",
      " |-- JobLevel: integer (nullable = true)\n",
      " |-- JobRole: string (nullable = true)\n",
      " |-- JobSatisfaction: integer (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- MonthlyIncome: integer (nullable = true)\n",
      " |-- MonthlyRate: integer (nullable = true)\n",
      " |-- NumCompaniesWorked: integer (nullable = true)\n",
      " |-- Over18: string (nullable = true)\n",
      " |-- OverTime: string (nullable = true)\n",
      " |-- PercentSalaryHike: integer (nullable = true)\n",
      " |-- PerformanceRating: integer (nullable = true)\n",
      " |-- RelationshipSatisfaction: integer (nullable = true)\n",
      " |-- StandardHours: integer (nullable = true)\n",
      " |-- StockOptionLevel: integer (nullable = true)\n",
      " |-- TotalWorkingYears: integer (nullable = true)\n",
      " |-- TrainingTimesLastYear: integer (nullable = true)\n",
      " |-- WorkLifeBalance: integer (nullable = true)\n",
      " |-- YearsAtCompany: integer (nullable = true)\n",
      " |-- YearsInCurrentRole: integer (nullable = true)\n",
      " |-- YearsSinceLastPromotion: integer (nullable = true)\n",
      " |-- YearsWithCurrManager: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d0d74ef-9fbf-4d4d-bdac-a0c9b791019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Age: int, Attrition: int, BusinessTravel: string, DailyRate: int, Department: string, DistanceFromHome: int, Education: int, EducationField: string, EmployeeCount: int, EmployeeNumber: int, EnvironmentSatisfaction: int, Gender: string, HourlyRate: int, JobInvolvement: int, JobLevel: int, JobRole: string, JobSatisfaction: int, MaritalStatus: string, MonthlyIncome: int, MonthlyRate: int, NumCompaniesWorked: int, Over18: string, OverTime: string, PercentSalaryHike: int, PerformanceRating: int, RelationshipSatisfaction: int, StandardHours: int, StockOptionLevel: int, TotalWorkingYears: int, TrainingTimesLastYear: int, WorkLifeBalance: int, YearsAtCompany: int, YearsInCurrentRole: int, YearsSinceLastPromotion: int, YearsWithCurrManager: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b24fe1-1125-4d16-8248-d0968cb93993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:27:19,974 - INFO - Ingesting data from C:\\excels\\test.csv as csv\n",
      "2025-01-07 16:27:21,644 - INFO - Data ingestion successful: C:\\excels\\test.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+---------+--------------------+----------------+---------+----------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|Age|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|  EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|\n",
      "+---+-----------------+---------+--------------------+----------------+---------+----------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "| 34|    Travel_Rarely|      790|               Sales|              24|        4|         Medical|            1|          1489|                      1|Female|        40|             2|       2|     Sales Executive|              2|       Single|         4599|       7815|                 0|     Y|     Yes|               23|                4|                       3|           80|               0|               16|                    2|              4|            15|                 9|                     10|                  10|\n",
      "| 35|    Travel_Rarely|      660|               Sales|               7|        1|   Life Sciences|            1|          1492|                      4|  Male|        76|             3|       1|Sales Representative|              3|      Married|         2404|      16192|                 1|     Y|      No|               13|                3|                       1|           80|               1|                1|                    3|              3|             1|                 0|                      0|                   0|\n",
      "| 24|Travel_Frequently|      381|Research & Develo...|               9|        3|         Medical|            1|          1494|                      2|  Male|        89|             3|       1|Laboratory Techni...|              1|       Single|         3172|      16998|                 2|     Y|     Yes|               11|                3|                       3|           80|               0|                4|                    2|              2|             0|                 0|                      0|                   0|\n",
      "| 24|       Non-Travel|      830|               Sales|              13|        2|   Life Sciences|            1|          1495|                      4|Female|        78|             3|       1|Sales Representative|              2|      Married|         2033|       7103|                 1|     Y|      No|               13|                3|                       3|           80|               1|                1|                    2|              3|             1|                 0|                      0|                   0|\n",
      "| 44|Travel_Frequently|     1193|Research & Develo...|               2|        1|         Medical|            1|          1496|                      2|  Male|        86|             3|       3|Manufacturing Dir...|              3|       Single|        10209|      19719|                 5|     Y|     Yes|               18|                3|                       2|           80|               0|               16|                    2|              2|             2|                 2|                      2|                   2|\n",
      "| 29|    Travel_Rarely|     1246|               Sales|              19|        3|   Life Sciences|            1|          1497|                      3|  Male|        77|             2|       2|     Sales Executive|              3|     Divorced|         8620|      23757|                 1|     Y|      No|               14|                3|                       3|           80|               2|               10|                    3|              3|            10|                 7|                      0|                   4|\n",
      "| 30|    Travel_Rarely|      330|     Human Resources|               1|        3|   Life Sciences|            1|          1499|                      3|  Male|        46|             3|       1|     Human Resources|              3|     Divorced|         2064|      15428|                 0|     Y|      No|               21|                4|                       1|           80|               1|                6|                    3|              4|             5|                 3|                      1|                   3|\n",
      "| 55|    Travel_Rarely|     1229|Research & Develo...|               4|        4|   Life Sciences|            1|          1501|                      4|  Male|        30|             3|       2|Healthcare Repres...|              3|      Married|         4035|      16143|                 0|     Y|     Yes|               16|                3|                       2|           80|               0|                4|                    2|              3|             3|                 2|                      1|                   2|\n",
      "| 33|    Travel_Rarely|     1099|Research & Develo...|               4|        4|         Medical|            1|          1502|                      1|Female|        82|             2|       1|Laboratory Techni...|              2|      Married|         3838|       8192|                 8|     Y|      No|               11|                3|                       4|           80|               0|                8|                    5|              3|             5|                 4|                      0|                   2|\n",
      "| 47|    Travel_Rarely|      571|               Sales|              14|        3|         Medical|            1|          1503|                      3|Female|        78|             3|       2|     Sales Executive|              3|      Married|         4591|      24200|                 3|     Y|     Yes|               17|                3|                       3|           80|               1|               11|                    4|              2|             5|                 4|                      1|                   2|\n",
      "| 28|Travel_Frequently|      289|Research & Develo...|               2|        2|         Medical|            1|          1504|                      3|  Male|        38|             2|       1|Laboratory Techni...|              1|       Single|         2561|       5355|                 7|     Y|      No|               11|                3|                       3|           80|               0|                8|                    2|              2|             0|                 0|                      0|                   0|\n",
      "| 28|    Travel_Rarely|     1423|Research & Develo...|               1|        3|   Life Sciences|            1|          1506|                      1|  Male|        72|             2|       1|  Research Scientist|              3|     Divorced|         1563|      12530|                 1|     Y|      No|               14|                3|                       4|           80|               1|                1|                    2|              1|             1|                 0|                      0|                   0|\n",
      "| 28|Travel_Frequently|      467|               Sales|               7|        3|   Life Sciences|            1|          1507|                      3|  Male|        55|             3|       2|     Sales Executive|              1|       Single|         4898|      11827|                 0|     Y|      No|               14|                3|                       4|           80|               0|                5|                    5|              3|             4|                 2|                      1|                   3|\n",
      "| 49|    Travel_Rarely|      271|Research & Develo...|               3|        2|         Medical|            1|          1509|                      3|Female|        43|             2|       2|Laboratory Techni...|              1|      Married|         4789|      23070|                 4|     Y|      No|               25|                4|                       1|           80|               1|               10|                    3|              3|             3|                 2|                      1|                   2|\n",
      "| 29|Travel_Frequently|      410|Research & Develo...|               2|        1|   Life Sciences|            1|          1513|                      4|Female|        97|             3|       1|Laboratory Techni...|              2|      Married|         3180|       4668|                 0|     Y|      No|               13|                3|                       3|           80|               3|                4|                    3|              3|             3|                 2|                      0|                   2|\n",
      "| 28|    Travel_Rarely|     1083|Research & Develo...|              29|        1|   Life Sciences|            1|          1514|                      3|  Male|        96|             1|       2|Manufacturing Dir...|              2|      Married|         6549|       3173|                 1|     Y|      No|               14|                3|                       2|           80|               2|                8|                    2|              2|             8|                 6|                      1|                   7|\n",
      "| 33|    Travel_Rarely|      516|Research & Develo...|               8|        5|   Life Sciences|            1|          1515|                      4|  Male|        69|             3|       2|Healthcare Repres...|              3|       Single|         6388|      22049|                 2|     Y|     Yes|               17|                3|                       1|           80|               0|               14|                    6|              3|             0|                 0|                      0|                   0|\n",
      "| 32|    Travel_Rarely|      495|Research & Develo...|              10|        3|         Medical|            1|          1516|                      3|  Male|        64|             3|       3|             Manager|              4|       Single|        11244|      21072|                 2|     Y|      No|               25|                4|                       2|           80|               0|               10|                    5|              4|             5|                 2|                      0|                   0|\n",
      "| 54|Travel_Frequently|     1050|Research & Develo...|              11|        4|         Medical|            1|          1520|                      2|Female|        87|             3|       4|             Manager|              4|     Divorced|        16032|      24456|                 3|     Y|      No|               20|                4|                       1|           80|               1|               26|                    2|              3|            14|                 9|                      1|                  12|\n",
      "| 29|    Travel_Rarely|      224|Research & Develo...|               1|        4|Technical Degree|            1|          1522|                      1|  Male|       100|             2|       1|  Research Scientist|              1|       Single|         2362|       7568|                 6|     Y|      No|               13|                3|                       3|           80|               0|               11|                    2|              1|             9|                 7|                      0|                   7|\n",
      "+---+-----------------+---------+--------------------+----------------+---------+----------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame2=ingest_data(spark,file_path=\"C:\\\\excels\\\\test.csv\",file_format='csv',options=csv_options)\n",
    "data_frame2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac30e627-25b6-4374-a61f-dc515f34d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data2=clean_data(data_frame2,columns_to_drop=[\"id\"],\n",
    "                        default_values=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b8a8cfc-98b9-4e12-8672-12696e96b8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- BusinessTravel: string (nullable = true)\n",
      " |-- DailyRate: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- DistanceFromHome: integer (nullable = true)\n",
      " |-- Education: integer (nullable = true)\n",
      " |-- EducationField: string (nullable = true)\n",
      " |-- EmployeeCount: integer (nullable = true)\n",
      " |-- EmployeeNumber: integer (nullable = true)\n",
      " |-- EnvironmentSatisfaction: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- HourlyRate: integer (nullable = true)\n",
      " |-- JobInvolvement: integer (nullable = true)\n",
      " |-- JobLevel: integer (nullable = true)\n",
      " |-- JobRole: string (nullable = true)\n",
      " |-- JobSatisfaction: integer (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- MonthlyIncome: integer (nullable = true)\n",
      " |-- MonthlyRate: integer (nullable = true)\n",
      " |-- NumCompaniesWorked: integer (nullable = true)\n",
      " |-- Over18: string (nullable = true)\n",
      " |-- OverTime: string (nullable = true)\n",
      " |-- PercentSalaryHike: integer (nullable = true)\n",
      " |-- PerformanceRating: integer (nullable = true)\n",
      " |-- RelationshipSatisfaction: integer (nullable = true)\n",
      " |-- StandardHours: integer (nullable = true)\n",
      " |-- StockOptionLevel: integer (nullable = true)\n",
      " |-- TotalWorkingYears: integer (nullable = true)\n",
      " |-- TrainingTimesLastYear: integer (nullable = true)\n",
      " |-- WorkLifeBalance: integer (nullable = true)\n",
      " |-- YearsAtCompany: integer (nullable = true)\n",
      " |-- YearsInCurrentRole: integer (nullable = true)\n",
      " |-- YearsSinceLastPromotion: integer (nullable = true)\n",
      " |-- YearsWithCurrManager: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49f01536-694c-4ef8-a31d-0fbe7d645749",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data=aggregate_data(cleaned_data,group_by_cols=['MonthlyIncome'],agg_funcs={\"MonthlyIncome\":avg,\"JobSatisfaction\":count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e057e540-77f4-4374-b116-c2e449a8e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data2=aggregate_data(cleaned_data,group_by_cols=[\"MonthlyIncome\"],agg_funcs={\"MonthlyIncome\":avg,\"JobSatisfaction\":count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8f135b-6616-4609-bff1-389ee18785ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data=join_data(data_frame,data_frame,'Department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2643d61-c5f4-4620-afea-53a8dab210f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Department: string, Age: int, Attrition: int, BusinessTravel: string, DailyRate: int, DistanceFromHome: int, Education: int, EducationField: string, EmployeeCount: int, EmployeeNumber: int, EnvironmentSatisfaction: int, Gender: string, HourlyRate: int, JobInvolvement: int, JobLevel: int, JobRole: string, JobSatisfaction: int, MaritalStatus: string, MonthlyIncome: int, MonthlyRate: int, NumCompaniesWorked: int, Over18: string, OverTime: string, PercentSalaryHike: int, PerformanceRating: int, RelationshipSatisfaction: int, StandardHours: int, StockOptionLevel: int, TotalWorkingYears: int, TrainingTimesLastYear: int, WorkLifeBalance: int, YearsAtCompany: int, YearsInCurrentRole: int, YearsSinceLastPromotion: int, YearsWithCurrManager: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c824289-2663-43a8-af67-dd621bca4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data=clean_data(joined_data,columns_to_drop=[\"Age\"],\n",
    "                        default_values=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e89aa35-2d03-4266-aeb9-813695eb0a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+---------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+---------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|Department|Attrition|BusinessTravel|DailyRate|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|        JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|\n",
      "+----------+---------+--------------+---------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+---------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "|     Sales|        1| Travel_Rarely|     1102|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "+----------+---------+--------------+---------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+---------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9f7c2d9-fc1d-43ab-89c2-b13c24388f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:27:30,174 - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2025-01-07 16:27:30,178 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "def save_data(df, output_path, file_format='csv', mode='overwrite'):\n",
    "    if file_format == 'csv':\n",
    "        \n",
    "        if mode == 'overwrite':\n",
    "            df.to_csv(output_path, index=False, mode='w')  # 'w' mode to overwrite\n",
    "        elif mode == 'append':\n",
    "            df.to_csv(output_path, index=False, mode='a', header=False)  # 'a' mode for appending\n",
    "\n",
    "    elif file_format == 'json':\n",
    "        \n",
    "        if mode == 'overwrite':\n",
    "            df.to_json(output_path, index=False, mode='w')  # 'w' mode to overwrite\n",
    "        elif mode == 'append':\n",
    "            df.to_json(output_path, index=False, mode='a')  # Append is not supported directly for Excel in Pandas\n",
    "\n",
    "    elif file_format == 'parquet':\n",
    "        # For Parquet, use the Pandas to_parquet method\n",
    "        if mode == 'overwrite':\n",
    "            df.to_parquet(output_path, index=False)\n",
    "        elif mode == 'append':\n",
    "            print(\"Append mode is not supported for Parquet format in Pandas.\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"Unsupported file format: {file_format}\")\n",
    "    \n",
    "    print(f\"Data saved successfully to {output_path}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5945106a-bc7e-40df-be69-520edb545599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(joined_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa2427ff-6c5e-46de-aae0-5f43b30c4358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(joined_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f552c24-7b08-4a04-8a4e-10846d64e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to C:\\jaiganesha\\output.csv\n",
      "Data saved successfully to C:\\jaiganesha\\output.json\n",
      "Data saved successfully to C:\\jaiganesha\\output.parquet\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "joined_data_panda = joined_data.toPandas()\n",
    "\n",
    "\n",
    "output_path = \"C:\\\\jaiganesha\\\\output.csv\"  \n",
    "save_data(joined_data_panda, output_path, file_format='csv', mode='overwrite')\n",
    "output_path1= \"C:\\\\jaiganesha\\\\output.json\"  \n",
    "save_data(joined_data_panda, output_path1, file_format='json', mode='overwrite')\n",
    "output_path = \"C:\\\\jaiganesha\\\\output.parquet\"  \n",
    "save_data(joined_data_panda, output_path, file_format='parquet', mode='overwrite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4e91952-c47b-4156-a818-9711d40ccbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 Results:\n",
      "+------+------------+\n",
      "|Gender|record_count|\n",
      "+------+------------+\n",
      "|  Male|      348622|\n",
      "|Female|      245984|\n",
      "+------+------------+\n",
      "\n",
      "Data saved successfully to C:\\jaiganesha\\output_query_1.csv\n",
      "Data saved successfully to C:\\jaiganesha\\output_query_1_p.parquet\n",
      "Data saved successfully to C:\\jaiganesha\\output_query_1_j.json\n"
     ]
    }
   ],
   "source": [
    "def run_analytics_queries(spark: SparkSession):\n",
    "    \n",
    "    df_1 = spark.read.csv(\"C:\\\\jaiganesha\\\\output.csv\", header=True, inferSchema=True)\n",
    "    df_1.createOrReplaceTempView(\"output_directory\")\n",
    "    \n",
    "   \n",
    "    schema = [\"JobRole\", \"metric_column\"]\n",
    "    data = [\n",
    "        (\"Sales Executive\", \"metric1\"),\n",
    "        (\"Research Scientist\", \"metric2\"),\n",
    "        (\"Laboratory Technician\", \"metric3\")\n",
    "    ]\n",
    "    df_2 = spark.createDataFrame(data, schema)\n",
    "    df_2.createOrReplaceTempView(\"another_directory\")\n",
    "\n",
    "  \n",
    "    query_1 = \"\"\"\n",
    "    SELECT  \n",
    "        Gender,  \n",
    "        COUNT(*) AS record_count  \n",
    "    FROM output_directory \n",
    "    GROUP BY Gender \n",
    "    ORDER BY record_count DESC\n",
    "    \"\"\" \n",
    "    result_1 = spark.sql(query_1)\n",
    "    print(\"Query 1 Results:\")\n",
    "    result_1.show()\n",
    "\n",
    " \n",
    "\n",
    "  \n",
    "    result_1_pandas = result_1.toPandas()\n",
    "   \n",
    "\n",
    "    \n",
    "    output_path_1 = \"C:\\\\jaiganesha\\\\output_query_1.csv\"\n",
    "    output_path_2 = \"C:\\\\jaiganesha\\\\output_query_1_p.parquet\"\n",
    "    output_path_3 = \"C:\\\\jaiganesha\\\\output_query_1_j.json\"\n",
    "    \n",
    "    \n",
    "    save_data(result_1_pandas, output_path_1, file_format='csv', mode='overwrite')\n",
    "    save_data(result_1_pandas, output_path_2, file_format='parquet', mode='overwrite')\n",
    "    save_data(result_1_pandas, output_path_3, file_format='json', mode='overwrite')\n",
    "    \n",
    "    \n",
    "    \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"My Data Warehouse Without Hive\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"C:\\\\jaiganesha\\\\spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "run_analytics_queries(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a375271e-9d44-4162-afaf-a9569a443f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Results:\n",
      "+--------------------+------+-----------------+\n",
      "|             JobRole|Gender|   avg_daily_rate|\n",
      "+--------------------+------+-----------------+\n",
      "|     Human Resources|Female|            989.0|\n",
      "|Healthcare Repres...|  Male|935.9795918367347|\n",
      "|             Manager|Female| 931.410907913902|\n",
      "|Manufacturing Dir...|  Male|862.4909090909091|\n",
      "|Laboratory Techni...|Female|       849.328125|\n",
      "|     Sales Executive|Female|836.8958333333334|\n",
      "|   Research Director|  Male|836.3243243243244|\n",
      "|Sales Representative|Female|816.8518518518518|\n",
      "|Healthcare Repres...|Female|816.6153846153846|\n",
      "|  Research Scientist|  Male|806.4444444444445|\n",
      "+--------------------+------+-----------------+\n",
      "\n",
      "Query results saved to: C:\\jaiganesha\\output_query_alternative.csv\n",
      "Query results saved to: C:\\jaiganesha\\output_query_alternative_p.parquet\n",
      "Query results saved to: C:\\jaiganesha\\output_query_alternative_j.json\n"
     ]
    }
   ],
   "source": [
    "def run_analytics_queries(spark: SparkSession):\n",
    "    \n",
    "    df_1 = spark.read.csv(\"C:\\\\jaiganesha\\\\output.csv\", header=True, inferSchema=True)\n",
    "    df_1.createOrReplaceTempView(\"output_directory\")\n",
    "\n",
    "   \n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        JobRole,\n",
    "        Gender,\n",
    "        AVG(DailyRate) AS avg_daily_rate\n",
    "    FROM output_directory\n",
    "    GROUP BY JobRole, Gender\n",
    "    ORDER BY avg_daily_rate DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    try:\n",
    "       \n",
    "        result = spark.sql(query)\n",
    "        print(\"Query Results:\")\n",
    "        result.show()\n",
    "\n",
    "        result_pandas = result.toPandas()\n",
    "        output_path = \"C:\\\\jaiganesha\\\\output_query_alternative.csv\"\n",
    "        result_pandas.to_csv(output_path, index=False)\n",
    "        print(f\"Query results saved to: {output_path}\")\n",
    "        output_path1 = \"C:\\\\jaiganesha\\\\output_query_alternative_p.parquet\"\n",
    "        result_pandas.to_csv(output_path1, index=False)\n",
    "        print(f\"Query results saved to: {output_path1}\")\n",
    "        output_path2=\"C:\\\\jaiganesha\\\\output_query_alternative_j.json\"\n",
    "        print(f\"Query results saved to: {output_path2}\")\n",
    "        result_pandas.to_json(output_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while executing the query: {e}\")\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"My Data Warehouse Without Hive\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"C:\\\\jaiganesha\\\\spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "run_analytics_queries(spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68209ed4-f0f4-48cf-90d9-54b8806b185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Query 1: Top Departments by Total Salary\n",
      "+--------------------+------------+\n",
      "|          Department|total_salary|\n",
      "+--------------------+------------+\n",
      "|Research & Develo...|   403068691|\n",
      "|               Sales|    80312397|\n",
      "|     Human Resources|     1130196|\n",
      "+--------------------+------------+\n",
      "\n",
      "Results saved to: C:\\jaiganesha\\Query_1_Top_Departments_by_Total_Salary.csv\n",
      "\n",
      "Results saved to: C:\\jaiganesha\\Query_1_Top_Departments_by_Total_Salary.parquet\n",
      "\n",
      "Executing: Query 2: Gender Distribution by JobRole\n",
      "+--------------------+------+------------+\n",
      "|             JobRole|Gender|gender_count|\n",
      "+--------------------+------+------------+\n",
      "|Healthcare Repres...|Female|       27339|\n",
      "|Healthcare Repres...|  Male|       34349|\n",
      "|     Human Resources|Female|         342|\n",
      "|     Human Resources|  Male|         798|\n",
      "|Laboratory Techni...|Female|       44864|\n",
      "|Laboratory Techni...|  Male|       86924|\n",
      "|             Manager|Female|       18537|\n",
      "|             Manager|  Male|       20460|\n",
      "|Manufacturing Dir...|Female|       36452|\n",
      "|Manufacturing Dir...|  Male|       38555|\n",
      "|   Research Director|Female|       17525|\n",
      "|   Research Director|  Male|       25937|\n",
      "|  Research Scientist|Female|       61688|\n",
      "|  Research Scientist|  Male|       88326|\n",
      "|     Sales Executive|Female|       30624|\n",
      "|     Sales Executive|  Male|       43384|\n",
      "|Sales Representative|Female|        8613|\n",
      "|Sales Representative|  Male|        9889|\n",
      "+--------------------+------+------------+\n",
      "\n",
      "Results saved to: C:\\jaiganesha\\Query_2_Gender_Distribution_by_JobRole.csv\n",
      "\n",
      "Results saved to: C:\\jaiganesha\\Query_2_Gender_Distribution_by_JobRole.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_additional_queries(spark: SparkSession):\n",
    "    # Load the dataset\n",
    "    df_1 = spark.read.csv(\"C:\\\\jaiganesha\\\\output.csv\", header=True, inferSchema=True)\n",
    "    df_1.createOrReplaceTempView(\"output_directory\")\n",
    "\n",
    "    # List of queries\n",
    "    queries = {\n",
    "        \"Query 1: Top Departments by Total Salary\": \"\"\"\n",
    "        SELECT Department, SUM(DailyRate) AS total_salary \n",
    "        FROM output_directory \n",
    "        GROUP BY Department \n",
    "        ORDER BY total_salary DESC \n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        ,\n",
    "        \"Query 2: Gender Distribution by JobRole\": \"\"\"\n",
    "        SELECT JobRole, Gender, COUNT(*) AS gender_count \n",
    "        FROM output_directory \n",
    "        GROUP BY JobRole, Gender \n",
    "        ORDER BY JobRole, Gender\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    for title, query in queries.items():\n",
    "        try:\n",
    "            print(f\"Executing: {title}\")\n",
    "            result = spark.sql(query)\n",
    "            result.show()\n",
    "\n",
    "            output_path = f\"C:\\\\jaiganesha\\\\{title.replace(':', '').replace(' ', '_')}.csv\"\n",
    "            result.toPandas().to_csv(output_path, index=False)\n",
    "            print(f\"Results saved to: {output_path}\\n\")\n",
    "            output_path1= f\"C:\\\\jaiganesha\\\\{title.replace(':', '').replace(' ', '_')}.parquet\"\n",
    "            result.toPandas().to_parquet(output_path1, index=False)\n",
    "            print(f\"Results saved to: {output_path1}\\n\")\n",
    "            output_path2 = f\"C:\\\\jaiganesha\\\\{title.replace(':', '').replace(' ', '_')}.json\"\n",
    "            result.toPandas().to_json(output_path2, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while executing {title}: {e}\")\n",
    "\n",
    "\n",
    "run_additional_queries(spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7675611a-1f3b-40ad-a7d0-fe06acbc4bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: Average Monthly Income by Department and Education Field\n",
      "+--------------------+----------------+------------------+\n",
      "|          Department|  EducationField|avg_monthly_income|\n",
      "+--------------------+----------------+------------------+\n",
      "|     Human Resources| Human Resources| 9138.066666666668|\n",
      "|     Human Resources|           Other|            7988.0|\n",
      "|               Sales|   Life Sciences| 7409.663366336634|\n",
      "|               Sales|       Marketing| 7348.131147540984|\n",
      "|     Human Resources|         Medical| 6909.888888888889|\n",
      "|     Human Resources|   Life Sciences| 6763.333333333333|\n",
      "|Research & Develo...|         Medical| 6698.923664122138|\n",
      "|               Sales|         Medical| 6462.152542372882|\n",
      "|Research & Develo...|           Other| 6371.744680851064|\n",
      "|Research & Develo...|Technical Degree| 6277.424242424242|\n",
      "|Research & Develo...|   Life Sciences| 6193.613496932516|\n",
      "|               Sales|Technical Degree| 5864.576923076923|\n",
      "|               Sales|           Other|            5745.0|\n",
      "|     Human Resources|Technical Degree|           3081.25|\n",
      "+--------------------+----------------+------------------+\n",
      "\n",
      "the output saved successfully to the pathC:\\jaiganesha\\avaragemonthlyincome.csv\n",
      "\n",
      "the output saved successfully to the pathC:\\jaiganesha\\avaragemonthlyincome_p.parquet\n",
      "\n",
      "the output saved successfully to the pathC:\\jaiganesha\\avaragemonthlyincome_j.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT \n",
    "    Department, \n",
    "    EducationField, \n",
    "    AVG(MonthlyIncome) AS avg_monthly_income \n",
    "FROM output_directory \n",
    "GROUP BY Department, EducationField \n",
    "ORDER BY avg_monthly_income DESC\n",
    "\"\"\"\n",
    "result_1 = spark.sql(query_1)\n",
    "print(\"Query 1: Average Monthly Income by Department and Education Field\")\n",
    "result_1.show()\n",
    "\n",
    "result1_p=result_1.toPandas()\n",
    "output_path= \"C:\\\\jaiganesha\\\\avaragemonthlyincome.csv\"\n",
    "result1_p.to_csv(output_path,index=False)\n",
    "print(f\"the output saved successfully to the path{output_path}\\n\")\n",
    "output_path1= \"C:\\\\jaiganesha\\\\avaragemonthlyincome_p.parquet\"\n",
    "result1_p.to_parquet(output_path1,index=False)\n",
    "print(f\"the output saved successfully to the path{output_path1}\\n\")\n",
    "output_path2= \"C:\\\\jaiganesha\\\\avaragemonthlyincome_j.json\"\n",
    "result1_p.to_json(output_path2,index=False)\n",
    "print(f\"the output saved successfully to the path{output_path2}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80c0d7d6-9051-4d16-abf7-6e59933b4207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 2: Top 5 Job Roles with Highest Satisfaction\n",
      "+--------------------+--------------------+\n",
      "|             JobRole|avg_job_satisfaction|\n",
      "+--------------------+--------------------+\n",
      "|Healthcare Repres...|  2.8295454545454546|\n",
      "|Laboratory Techni...|  2.8138297872340425|\n",
      "|  Research Scientist|  2.7803738317757007|\n",
      "|Sales Representative|  2.7586206896551726|\n",
      "|     Sales Executive|  2.7543103448275863|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "output saved to\tC:\\jaiganesha\\satisfactionjobavg.csv\n",
      "\n",
      "output saved to\tC:\\jaiganesha\\satisfactionjobavg_p.parquet\n",
      "\n",
      "the output saved successfully to the pathC:\\jaiganesha\\satisfactionjobavg_j.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_2 = \"\"\"\n",
    "SELECT \n",
    "    JobRole, \n",
    "    AVG(JobSatisfaction) AS avg_job_satisfaction \n",
    "FROM output_directory \n",
    "GROUP BY JobRole \n",
    "ORDER BY avg_job_satisfaction DESC \n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "result_2 = spark.sql(query_2)\n",
    "print(\"Query 2: Top 5 Job Roles with Highest Satisfaction\")\n",
    "result_2.show()\n",
    "\n",
    "result2_p=result_2.toPandas()\n",
    "output_path=\"C:\\\\jaiganesha\\\\satisfactionjobavg.csv\"\n",
    "result2_p.to_csv(output_path,index=False)\n",
    "print(f\"output saved to\\t{output_path}\\n\")\n",
    "output_path1=\"C:\\\\jaiganesha\\\\satisfactionjobavg_p.parquet\"\n",
    "result2_p.to_parquet(output_path1,index=False)\n",
    "print(f\"output saved to\\t{output_path1}\\n\")\n",
    "output_path2= \"C:\\\\jaiganesha\\\\satisfactionjobavg_j.json\"\n",
    "result2_p.to_json(output_path2,index=False)\n",
    "print(f\"the output saved successfully to the path{output_path2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4375036e-9039-4650-906f-64cca58e95b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 3: Gender Distribution Across Job Levels\n",
      "+--------+------+------+\n",
      "|JobLevel|Gender| count|\n",
      "+--------+------+------+\n",
      "|       1|  Male|153513|\n",
      "|       1|Female| 90119|\n",
      "|       2|  Male|101552|\n",
      "|       2|Female| 84132|\n",
      "|       3|  Male| 49708|\n",
      "|       3|Female| 39621|\n",
      "|       4|  Male| 24195|\n",
      "|       4|Female| 20346|\n",
      "|       5|  Male| 19654|\n",
      "|       5|Female| 11766|\n",
      "+--------+------+------+\n",
      "\n",
      "the output saved to\tC:\\jaiganesha\\joblevel.csv\n",
      "\n",
      "the output saved to\tC:\\jaiganesha\\joblevel_p.parquet\n",
      "\n",
      "the output saved successfully to the pathC:\\jaiganesha\\avaragemonthlyincome_p.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_3 = \"\"\"\n",
    "SELECT \n",
    "    JobLevel, \n",
    "    Gender, \n",
    "    COUNT(*) AS count \n",
    "FROM output_directory \n",
    "GROUP BY JobLevel, Gender \n",
    "ORDER BY JobLevel, count DESC\n",
    "\"\"\"\n",
    "result_3 = spark.sql(query_3)\n",
    "print(\"Query 3: Gender Distribution Across Job Levels\")\n",
    "result_3.show()\n",
    "\n",
    "result3_p=result_3.toPandas()\n",
    "output_path=\"C:\\\\jaiganesha\\\\joblevel.csv\"\n",
    "result3_p.to_csv(output_path,index=False)\n",
    "print(f\"the output saved to\\t{output_path}\\n\")\n",
    "output_path1=\"C:\\\\jaiganesha\\\\joblevel_p.parquet\"\n",
    "result3_p.to_parquet(output_path1,index=False)\n",
    "print(f\"the output saved to\\t{output_path1}\\n\")\n",
    "output_path2= \"C:\\\\jaiganesha\\\\avaragemonthlyincome_p.parquet\"\n",
    "result1_p.to_parquet(output_path1,index=False)\n",
    "print(f\"the output saved successfully to the path{output_path2}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a814722c-10d4-468d-b2fe-678bb1017600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 4: Relationship Between OverTime and Performance Rating\n",
      "+--------+----------------------+\n",
      "|OverTime|avg_performance_rating|\n",
      "+--------+----------------------+\n",
      "|      No|    3.1585016947216085|\n",
      "|     Yes|    3.1505805889567737|\n",
      "+--------+----------------------+\n",
      "\n",
      "output saved to\tC:\\jaiganesha\\performance.csv\n",
      "\n",
      "output saved to\tC:\\jaiganesha\\performance_p.parquet\n",
      "\n",
      "output saved to\tC:\\jaiganesha\\performance_j.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_4 = \"\"\"\n",
    "SELECT \n",
    "    OverTime, \n",
    "    AVG(PerformanceRating) AS avg_performance_rating \n",
    "FROM output_directory \n",
    "GROUP BY OverTime \n",
    "ORDER BY avg_performance_rating DESC\n",
    "\"\"\"\n",
    "result_4 = spark.sql(query_4)\n",
    "print(\"Query 4: Relationship Between OverTime and Performance Rating\")\n",
    "result_4.show()\n",
    "result4_p=result_4.toPandas()\n",
    "output_path=\"C:\\\\jaiganesha\\\\performance.csv\"\n",
    "result4_p.to_csv(output_path,index=False)\n",
    "print(f\"output saved to\\t{output_path}\\n\")\n",
    "output_path1=\"C:\\\\jaiganesha\\\\performance_p.parquet\"\n",
    "result4_p.to_csv(output_path1,index=False)\n",
    "print(f\"output saved to\\t{output_path1}\\n\")\n",
    "output_path2=\"C:\\\\jaiganesha\\\\performance_j.json\"\n",
    "result4_p.to_csv(output_path2,index=False)\n",
    "print(f\"output saved to\\t{output_path2}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7aae4c8-f50e-4278-932e-870e8ef71adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 5: Attrition Risk Indicators\n",
      "+-----------------+--------------+--------------+\n",
      "|TotalWorkingYears|YearsAtCompany|employee_count|\n",
      "+-----------------+--------------+--------------+\n",
      "|               10|            10|         32737|\n",
      "|                1|             1|         31906|\n",
      "|                6|             5|         17387|\n",
      "|                6|             6|         13487|\n",
      "|                5|             5|         13361|\n",
      "|                2|             2|         13168|\n",
      "|                8|             8|         12085|\n",
      "|                9|             9|         11984|\n",
      "|               10|             9|         11027|\n",
      "|                5|             4|          9306|\n",
      "|               10|             8|          8987|\n",
      "|                4|             4|          8668|\n",
      "|                4|             3|          8618|\n",
      "|                5|             3|          8349|\n",
      "|                3|             3|          7459|\n",
      "|                6|             2|          6628|\n",
      "|                8|             5|          6540|\n",
      "|               10|             7|          6347|\n",
      "|                9|             8|          6120|\n",
      "|                7|             7|          5839|\n",
      "+-----------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "output saved to path\tC:\\jaiganesha\\riskindicator.csv\n",
      "\n",
      "output saved to path\tC:\\jaiganesha\\riskindicator.csv\n",
      "\n",
      "output saved to path\tC:\\jaiganesha\\riskindicator_j.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_5 = \"\"\"\n",
    "SELECT \n",
    "    TotalWorkingYears, \n",
    "    YearsAtCompany, \n",
    "    COUNT(*) AS employee_count \n",
    "FROM output_directory \n",
    "GROUP BY TotalWorkingYears, YearsAtCompany \n",
    "ORDER BY employee_count DESC\n",
    "\"\"\"\n",
    "result_5 = spark.sql(query_5)\n",
    "print(\"Query 5: Attrition Risk Indicators\")\n",
    "result_5.show()\n",
    "result5_p=result_5.toPandas()\n",
    "output_path=\"C:\\\\jaiganesha\\\\riskindicator.csv\"\n",
    "result5_p.to_csv(output_path,index=False)\n",
    "print(f\"output saved to path\\t{output_path}\\n\")\n",
    "output_path1=\"C:\\\\jaiganesha\\\\riskindicator_p.parquet\"\n",
    "result5_p.to_csv(output_path1,index=False)\n",
    "print(f\"output saved to path\\t{output_path}\\n\")\n",
    "output_path2=\"C:\\\\jaiganesha\\\\riskindicator_j.json\"\n",
    "result5_p.to_csv(output_path2,index=False)\n",
    "print(f\"output saved to path\\t{output_path2}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "303667b7-b3e3-442d-8d53-2c6020fdc2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pip in c:\\users\\akshata pandit\\appdata\\roaming\\python\\python311\\site-packages (24.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a48d2e7e-c00a-4e21-89e4-5cdcbd1870cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to C:\\jaiganesha\\output_p.parquet\n"
     ]
    }
   ],
   "source": [
    "output_path = \"C:\\\\jaiganesha\\\\output_p.parquet\"  \n",
    "save_data(joined_data_panda, output_path, file_format='parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc5cd007-26f3-4b39-9432-4c5cf20d783b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timezone('UTC')\n"
     ]
    }
   ],
   "source": [
    "import pendulum\n",
    "print(pendulum.timezone(\"UTC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "693b3fd1-6560-40ff-9d02-e73e0b824bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command_with_daemon_option(cmd, daemon, pid):\n",
    "    import subprocess\n",
    "    subprocess.Popen(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08124181-1f34-47a4-ba31-ea050540c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: luigi in c:\\users\\akshata pandit\\appdata\\roaming\\python\\python311\\site-packages (3.6.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from luigi) (2.8.2)\n",
      "Requirement already satisfied: tenacity<9,>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from luigi) (8.2.2)\n",
      "Requirement already satisfied: tornado<7,>=5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from luigi) (6.3.3)\n",
      "Requirement already satisfied: python-daemon in c:\\users\\akshata pandit\\appdata\\roaming\\python\\python311\\site-packages (from luigi) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.5->luigi) (1.16.0)\n",
      "Requirement already satisfied: lockfile>=0.10 in c:\\users\\akshata pandit\\appdata\\roaming\\python\\python311\\site-packages (from python-daemon->luigi) (0.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip install luigi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9111df16-fdfe-4973-a0a9-4662d4ef3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:30:00,667 - INFO - Loaded []\n"
     ]
    }
   ],
   "source": [
    "import luigi\n",
    "import time\n",
    "\n",
    "\n",
    "class FetchDataTask(luigi.Task):\n",
    "    output_file = luigi.Parameter()\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Fetching data and writing to {self.output_file}\")\n",
    "        \n",
    "        with open(self.output_file, 'w') as f:\n",
    "            f.write(\"Simulated data\\n\")\n",
    "        time.sleep(2)\n",
    "\n",
    "class ProcessDataTask(luigi.Task):\n",
    "    input_file = luigi.Parameter()\n",
    "    output_file = luigi.Parameter()\n",
    "\n",
    "    def requires(self):\n",
    "        \n",
    "        return FetchDataTask(output_file=self.input_file)\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Processing data from {self.input_file} and saving to {self.output_file}\")\n",
    "        with open(self.input_file, 'r') as f:\n",
    "            data = f.read()\n",
    "\n",
    "        # Simulating data processing\n",
    "        processed_data = data.upper()  # Convert text to uppercase\n",
    "        \n",
    "        with open(self.output_file, 'w') as f:\n",
    "            f.write(processed_data)\n",
    "        time.sleep(2)\n",
    "\n",
    "# Task C: Store the processed data\n",
    "class StoreDataTask(luigi.Task):\n",
    "    input_file = luigi.Parameter()\n",
    "\n",
    "    def requires(self):\n",
    "        # This task depends on ProcessDataTask\n",
    "        return ProcessDataTask(input_file='raw_data.txt', output_file='processed_data.txt')\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Storing processed data from {self.input_file}\")\n",
    "        with open(self.input_file, 'r') as f:\n",
    "            data = f.read()\n",
    "\n",
    "        # Simulating storing the data\n",
    "        with open('final_data.txt', 'w') as f:\n",
    "            f.write(data)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2c259-30fa-4800-95ce-433edc418099",
   "metadata": {},
   "source": [
    "#  Run the pipeline\n",
    "To execute the pipeline, run the following command in your terminal:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "python pipeline.py StoreDataTask --input-file=raw_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b70fe8a-e339-442c-a445-f4ecd7f23733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 16:30:02,531 - INFO - Total rows processed: 1058\n",
      "2025-01-07 16:30:02,534 - INFO - Null counts: [Row(Age=0, Attrition=0, BusinessTravel=0, DailyRate=0, Department=0, DistanceFromHome=0, Education=0, EducationField=0, EmployeeCount=0, EmployeeNumber=0, EnvironmentSatisfaction=0, Gender=0, HourlyRate=0, JobInvolvement=0, JobLevel=0, JobRole=0, JobSatisfaction=0, MaritalStatus=0, MonthlyIncome=0, MonthlyRate=0, NumCompaniesWorked=0, Over18=0, OverTime=0, PercentSalaryHike=0, PerformanceRating=0, RelationshipSatisfaction=0, StandardHours=0, StockOptionLevel=0, TotalWorkingYears=0, TrainingTimesLastYear=0, WorkLifeBalance=0, YearsAtCompany=0, YearsInCurrentRole=0, YearsSinceLastPromotion=0, YearsWithCurrManager=0)]\n",
      "2025-01-07 16:30:03,834 - INFO - Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when\n",
    "import logging\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"SparkJobMonitor\")\n",
    "\n",
    "# Email Alert Function\n",
    "def send_email_alert(subject, body):\n",
    "    sender_email = \"akshatapandit7@gmail.com\"\n",
    "    receiver_email = \"akshata.codes2332@gmail.com\"\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    smtp_port = 587\n",
    "    smtp_password = \"your_email_password\"\n",
    "\n",
    "    msg = EmailMessage()\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "    msg.set_content(body)\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, smtp_password)\n",
    "            server.send_message(msg)\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to send email alert: {e}\")\n",
    "\n",
    "# Spark Job Execution and Monitoring\n",
    "def run_spark_job():\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"AlternativeSparkMonitoring\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    try:\n",
    "        \n",
    "        data_path = \"C:\\\\excels\\\\train.csv\"\n",
    "        df = spark.read.csv(data_path, header=True)\n",
    "\n",
    "        total_rows = df.count()\n",
    "        null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).collect()\n",
    "\n",
    "        logger.info(f\"Total rows processed: {total_rows}\")\n",
    "        logger.info(f\"Null counts: {null_counts}\")\n",
    "\n",
    "        # Alert if row count is below a threshold\n",
    "        if total_rows < 1000:\n",
    "            alert_message = f\"ALERT: Row count below threshold! Processed rows: {total_rows}\"\n",
    "            logger.warning(alert_message)\n",
    "            send_email_alert(\"Row Count Alert\", alert_message)\n",
    "\n",
    "        # Alert if null values exceed a threshold\n",
    "        for column, null_count in zip(df.columns, null_counts[0]):\n",
    "            if null_count > 0:\n",
    "                alert_message = f\"ALERT: Null values detected in column '{column}': {null_count}\"\n",
    "                logger.warning(alert_message)\n",
    "                send_email_alert(\"Data Quality Alert\", alert_message)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Spark job encountered an error: {e}\")\n",
    "        send_email_alert(\"Job Failure Alert\", f\"Spark job failed with error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        spark.stop()\n",
    "        logger.info(\"Spark session stopped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_spark_job()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69a6861-0b58-4e2a-af62-602853a58c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
